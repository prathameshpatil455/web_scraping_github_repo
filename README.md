# GitHub Repository Web Scraping

## Overview

The GitHub Repository Web Scraping project is aimed at extracting information about the top repositories on GitHub based on various criteria such as stars, trending status, etc. The extracted data includes repository titles, descriptions, star counts, and URLs, providing valuable insights into popular GitHub projects across different domains.

## Features

- **Web Scraping:** The project utilizes web scraping techniques to extract repository information directly from the GitHub website, enabling automated data collection.

- **Top Repositories:** The script retrieves information about the top repositories based on specified criteria, such as stars, trending status, etc., providing users with a curated list of popular GitHub projects.

- **Data Extraction:** Extracted data includes repository titles, descriptions, star counts, and URLs, facilitating further analysis and exploration of GitHub repositories.

## Preview
![Screenshot 1](https://github.com/prathameshpatil455/web_scraping_github_repo/blob/main/screenshots/Screenshot%202024-04-08%20183448.png)

## Installation

1. Clone the repository from GitHub:

    ```bash
    git clone https://github.com/yourusername/github-repo-web-scraping.git
    ```

2. Navigate to the project directory:

    ```bash
    cd github-repo-web-scraping
    ```

3. Install dependencies:

    ```bash
    pip install -r requirements.txt
    ```

## Technologies Used

- **Python:** Primary programming language for web scraping and data extraction tasks.
  
- **Beautiful Soup:** Python library for parsing HTML and XML documents, used for web scraping GitHub repositories.
  
- **Requests:** HTTP library for making requests to web servers, used for fetching GitHub web pages.

## Acknowledgements

- Thanks to GitHub for providing a rich source of open-source repositories and relevant data.
  
- Special thanks to the creators and maintainers of Beautiful Soup and Requests libraries for facilitating web scraping tasks.

